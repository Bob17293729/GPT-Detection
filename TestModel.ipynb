{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1q3EZIrQEJaoDIj8M09tLrtzCr3MpmBI1","authorship_tag":"ABX9TyOx1lmhxvOFYkf3One6u6+T"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"la6PpRUY-CvX","executionInfo":{"status":"ok","timestamp":1683725669936,"user_tz":-480,"elapsed":22404,"user":{"displayName":"鲍宗博","userId":"16723521924283406417"}},"outputId":"692220c0-fdea-4ccf-b03a-5ea493032440"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Collecting huggingface-hub<1.0,>=0.11.0 (from transformers)\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m107.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n"]}],"source":["# get baseline model\n","import torch\n","!pip install transformers\n","import transformers\n","from transformers import RobertaForSequenceClassification, RobertaTokenizer\n","# base_model_path = \"/content/drive/MyDrive/CSC3160/GPT-Detection/Baseline/best_model.pt\"\n","# def load_model(model_path):\n","#     # Load the tokenizer and model from the \"roberta-base\" pre-trained model\n","#     tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n","#     model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\").cuda()\n","\n","#     # Load the saved state dict of the fine-tuned model\n","#     model.load_state_dict(torch.load(model_path))\n","\n","#     return tokenizer, model\n","# base_tokenizer,base_model = load_model(base_model_path)\n"]},{"cell_type":"code","source":["from transformers import AutoTokenizer, GPT2LMHeadModel\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n","model = GPT2LMHeadModel.from_pretrained(\"gpt2\")"],"metadata":{"id":"5GxHx4W03Ycq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Text = \"\\n\\nAs a sophomore in high school, I harboured a fervent desire to throw my hat into the ring for the student council president position, confident in my abilities honed from being an active council participant. Tragically, my hopes and aspirations were tampered by deceitful rumors and vandalized posters disseminated by a rival competitor- sour incidents which left me crestfallen and defeated.\\n\\nInitially, I was overwhelmed by a wave of despondency. I had signalled considerable zeal and assiduity to the campaign and its outcome yet the universe seemed intent on dealing me a harsh blow. However, like a Phoenix reborn from the ashes, my ordeal galvanized unyielding reflections the essence of which unveiled invaluable life lessons. Above all, I gleaned the notion that the existence of antagonizing forces shouldn't diminish the potency of my ambition. More importantly, I discovered that leadership goes beyond postulations of titles and credentials. Revealingly, I remained a well-engaged council member, steadfastly championing worthy causes that resonated with my person.\\n\\nThe crowning lesson that emerged from my ordeal was gravity's rapacious generational appetite for failure, not being modestly egalitarian in its distribution. The experience in its entirety had gifted me a dimension of emotional depth that defied age, as I realised that my set back was not an expiration of my ambition or an indictment of my leadership capabilities; but a springboard into greater things. Now, with even more conviction, I am resolved in putting one foot in front of the other on the path to my goals. In summation, though my student council campaign was challenging, it proved to be a crucible of growth that refined my leadership capacity.\""],"metadata":{"id":"lZky0kzKhd5E","executionInfo":{"status":"ok","timestamp":1683680968690,"user_tz":-480,"elapsed":5,"user":{"displayName":"鲍宗博","userId":"16723521924283406417"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["inputs = tokenizer(Text, return_tensors=\"pt\")\n","outputs = model(**inputs, labels=inputs[\"input_ids\"])\n","loss = outputs.loss\n","logits = outputs.logits"],"metadata":{"id":"NzN_8SmxWRvl","executionInfo":{"status":"ok","timestamp":1683680972400,"user_tz":-480,"elapsed":998,"user":{"displayName":"鲍宗博","userId":"16723521924283406417"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["outputs.hidden_states"],"metadata":{"id":"ix-i0hKTTHBV","executionInfo":{"status":"ok","timestamp":1683681317973,"user_tz":-480,"elapsed":980,"user":{"displayName":"鲍宗博","userId":"16723521924283406417"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def get_rank(inputs, outputs):\n","    # input is a tensor of shape (1,n), n is the number of words in the input, each element is the index of the word in the vocabulary\n","    # output.logits is a tensor of shape (1, n, vocab_size), each element is the logit of the word in the vocabulary\n","    # we need to get the rank of input id in the output.logits\n","    # output is a tensor of shape (1, n), n is the number of words in the input\n","    # get the rank of each real word in the prediction of gpt2 model\n","    length = inputs.shape[1]\n","    rank = torch.zeros(length)\n","    logits = outputs.logits\n","    for i in range(length):\n","        word = inputs[0][i]\n","        logit = logits[0][i]\n","        rank[i] = torch.sum(logit > logit[word])\n","    return rank"],"metadata":{"id":"uOSOP-CnWo1V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rank = get_rank(inputs[\"input_ids\"], outputs)"],"metadata":{"id":"Q9dHTZfucICB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Get single sample\n","Text = \"\\n\\nAs a sophomore in high school, I harboured a fervent desire to throw my hat into the ring for the student council president position, confident in my abilities honed from being an active council participant. Tragically, my hopes and aspirations were tampered by deceitful rumors and vandalized posters disseminated by a rival competitor- sour incidents which left me crestfallen and defeated.\\n\\nInitially, I was overwhelmed by a wave of despondency. I had signalled considerable zeal and assiduity to the campaign and its outcome yet the universe seemed intent on dealing me a harsh blow. However, like a Phoenix reborn from the ashes, my ordeal galvanized unyielding reflections the essence of which unveiled invaluable life lessons. Above all, I gleaned the notion that the existence of antagonizing forces shouldn't diminish the potency of my ambition. More importantly, I discovered that leadership goes beyond postulations of titles and credentials. Revealingly, I remained a well-engaged council member, steadfastly championing worthy causes that resonated with my person.\\n\\nThe crowning lesson that emerged from my ordeal was gravity's rapacious generational appetite for failure, not being modestly egalitarian in its distribution. The experience in its entirety had gifted me a dimension of emotional depth that defied age, as I realised that my set back was not an expiration of my ambition or an indictment of my leadership capabilities; but a springboard into greater things. Now, with even more conviction, I am resolved in putting one foot in front of the other on the path to my goals. In summation, though my student council campaign was challenging, it proved to be a crucible of growth that refined my leadership capacity.\"\n","label = 1"],"metadata":{"id":"yLXc_tkj-EuD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Test on a single sample\n","import numpy as np\n","def preprocess_text(tokenizer, input_text, max_length):\n","    # Tokenize the input text using the tokenizer\n","    inputs = tokenizer.encode_plus(\n","        input_text,\n","        add_special_tokens=True,\n","        return_tensors=\"pt\",\n","        max_length=max_length,\n","        truncation=True,\n","    )\n","\n","    # Get the input_ids and attention_mask tensors\n","    return inputs[\"input_ids\"].cuda(), inputs[\"attention_mask\"].cuda()\n","\n","def get_prediction(model, input_ids, attention_mask):\n","    # Get the predicted label using the input_ids and attention_mask\n","    outputs = model(input_ids, attention_mask=attention_mask)\n","    predicted_label = np.argmax(outputs.logits.detach().cpu().numpy())\n","    return predicted_label\n","\n"],"metadata":{"id":"pj3QWgVZEG9N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_ids, attention_mask = preprocess_text(\n","                base_tokenizer, Text, max_length=512\n","            )\n","predicted_label = get_prediction(base_model, input_ids, attention_mask)\n","if predicted_label == 0:\n","  print(\"human\")\n","else:\n","  print(\"chatGPT\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dChVO5Ps9Vi9","executionInfo":{"status":"ok","timestamp":1682418534891,"user_tz":-480,"elapsed":2180,"user":{"displayName":"鲍宗博","userId":"16723521924283406417"}},"outputId":"59671bf3-72b7-449e-ab0d-a82d0acbde5a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["chatGPT\n"]}]},{"cell_type":"code","source":["# Get Test data\n","file_path = \"/content/drive/MyDrive/CSC3160/GPT-Detection/Baseline/Essay_data/human_data/TOEFL_real_91/data.json\""],"metadata":{"id":"YmLSI_S_FrGe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json\n","def get_data(file_path,is_gpt = True):\n","  with open(file_path,\"r\") as f:\n","    data = json.load(f)\n","    examples = []\n","    for example in data:\n","      text = example[\"document\"]\n","      label = is_gpt\n","    examples.append({\"text\":text,\"label\":label})\n","  return examples\n","\n"],"metadata":{"id":"Sk4A1A_IHhQ4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate_model(file_path, tokenizer = base_tokenizer, model = base_model, is_gpt = True):\n","  result = []\n","  dataset = get_data(file_path,is_gpt)\n","  for data in dataset:\n","    input_ids, attention_mask = preprocess_text(\n","                tokenizer, data[\"text\"], max_length=512\n","            )\n","    predicted_label = get_prediction(model, input_ids, attention_mask)\n","    result.append(predicted_label)\n","  if not is_gpt:\n","    accuracy = 1-sum(result)/len(result)\n","  else:\n","    accuracy = sum(result)/len(result)\n","  return accuracy\n","\n","\n"],"metadata":{"id":"Qupk0rvILVn2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["accuracy = evaluate_model(file_path,is_gpt = False)\n","print(f\"Accuracy at{file_path}:\\n {accuracy:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rqZybLpBO8zl","executionInfo":{"status":"ok","timestamp":1682087994466,"user_tz":-480,"elapsed":624,"user":{"displayName":"鲍宗博","userId":"16723521924283406417"}},"outputId":"febf5bd4-70ec-4c92-d248-ad623ac07684"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy at/content/drive/MyDrive/CSC3160/GPT-Detection/Baseline/Essay_data/human_data/TOEFL_real_91/data.json:\n"," 0.0000\n"]}]}]}